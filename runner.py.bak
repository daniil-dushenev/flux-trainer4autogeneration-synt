"""
Главный скрипт для запуска пайплайна генерации синтетических данных.
"""
import argparse
from pathlib import Path
from typing import Optional
import logging

# Настраиваем окружение для скачивания на диск D
try:
    from setup_env import *
except ImportError:
    # Если setup_env не найден, пытаемся импортировать из текущей директории
    import sys
    import os
    sys.path.insert(0, os.path.dirname(__file__))
    from setup_env import *

from data_preparation import TrainingDataPreparator
from lora_training import FluxLoRATrainer, LoRATrainingConfig
from generation import SyntheticImageGenerator
from output_handler import OutputHandler


logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def run_synthetic_generation_pipeline(
    jsonl_path: str | Path,
    output_dir: str | Path,
    images_root: Optional[str | Path] = None,
    lora_output_dir: Optional[str | Path] = None,
    lora_path: Optional[str | Path] = None,
    skip_training: bool = False,
    num_samples_to_generate: Optional[int] = None,
    training_config: Optional[LoRATrainingConfig] = None,
    controlnet_types: Optional[list[str]] = None,
    generation_params: Optional[dict] = None,
):
    """
    Запускает полный пайплайн генерации синтетических данных.
    
    Args:
        jsonl_path: Путь к predictions.jsonl с размеченными данными
        output_dir: Директория для сохранения результатов
        images_root: Корневая папка с изображениями
        lora_output_dir: Директория для сохранения LoRA адаптера
        lora_path: Путь к уже обученному LoRA адаптеру (если skip_training=True)
        skip_training: Пропустить обучение и использовать существующий адаптер
        num_samples_to_generate: Количество сэмплов для генерации (None = все)
        training_config: Конфигурация обучения (по умолчанию используется стандартная)
        controlnet_types: Типы ControlNet условий (["canny", "depth"])
        generation_params: Параметры генерации (num_inference_steps, guidance_scale, seed)
    """
    logger.info("Starting synthetic data generation pipeline")
    
    # Инициализируем параметры по умолчанию
    controlnet_types = controlnet_types or ["canny", "depth"]
    generation_params = generation_params or {
        "num_inference_steps": 50,
        "guidance_scale": 7.5,
        "seed": None,
    }
    
    # Шаг 1: Подготовка данных
    logger.info("Step 1: Preparing data")
    preparator = TrainingDataPreparator(
        jsonl_path=jsonl_path,
        images_root=images_root,
        controlnet_types=controlnet_types,
    )
    
    samples = preparator.prepare_all()
    logger.info(f"Prepared {len(samples)} training samples")
    
    if num_samples_to_generate:
        samples = samples[:num_samples_to_generate]
        logger.info(f"Limiting to {num_samples_to_generate} samples for generation")
    
    # Шаг 2: Обучение LoRA адаптера (если нужно)
    if not skip_training:
        logger.info("Step 2: Training LoRA adapter")
        
        if training_config is None:
            training_config = LoRATrainingConfig(
                controlnet_types=controlnet_types,
            )
        
        if lora_output_dir:
            training_config.output_dir = str(lora_output_dir)
        
        trainer = FluxLoRATrainer(training_config)
        lora_path = trainer.train(samples)
        trainer.save_config()
        logger.info(f"LoRA adapter trained and saved to {lora_path}")
    else:
        if lora_path is None:
            raise ValueError("lora_path must be provided when skip_training=True")
        logger.info(f"Step 2: Skipping training, using existing LoRA at {lora_path}")
    
    # Шаг 3: Генерация синтетических изображений
    logger.info("Step 3: Generating synthetic images")
    
    generator = SyntheticImageGenerator(
        lora_path=lora_path,
        controlnet_types=controlnet_types,
    )
    
    generated_images = generator.generate_batch(
        samples,
        num_inference_steps=generation_params.get("num_inference_steps", 50),
        guidance_scale=generation_params.get("guidance_scale", 7.5),
        seed=generation_params.get("seed"),
    )
    logger.info(f"Generated {len(generated_images)} images")
    
    # Шаг 4: Сохранение результатов
    logger.info("Step 4: Saving results")
    
    output_handler = OutputHandler(output_dir)
    saved_ids = output_handler.save_batch(
        images=generated_images,
        samples=samples,
        lora_path=str(lora_path),
    )
    logger.info(f"Saved {len(saved_ids)} images to {output_dir}")
    
    logger.info("Pipeline completed successfully!")


def main():
    """Точка входа для запуска из командной строки."""
    parser = argparse.ArgumentParser(
        description="Генерация синтетических данных через FLUX + LoRA + ControlNet"
    )
    
    parser.add_argument(
        "jsonl_path",
        type=str,
        help="Путь к predictions.jsonl с размеченными данными"
    )
    
    parser.add_argument(
        "output_dir",
        type=str,
        help="Директория для сохранения результатов"
    )
    
    parser.add_argument(
        "--images-root",
        type=str,
        default=None,
        help="Корневая папка с изображениями (опционально)"
    )
    
    parser.add_argument(
        "--lora-output-dir",
        type=str,
        default=None,
        help="Директория для сохранения LoRA адаптера"
    )
    
    parser.add_argument(
        "--lora-path",
        type=str,
        default=None,
        help="Путь к уже обученному LoRA адаптеру (если --skip-training)"
    )
    
    parser.add_argument(
        "--skip-training",
        action="store_true",
        help="Пропустить обучение и использовать существующий адаптер"
    )
    
    parser.add_argument(
        "--num-samples",
        type=int,
        default=None,
        help="Количество сэмплов для генерации (по умолчанию все)"
    )
    
    parser.add_argument(
        "--controlnet-types",
        nargs="+",
        default=["canny", "depth"],
        choices=["canny", "depth"],
        help="Типы ControlNet условий"
    )
    
    parser.add_argument(
        "--num-inference-steps",
        type=int,
        default=50,
        help="Количество шагов генерации"
    )
    
    parser.add_argument(
        "--guidance-scale",
        type=float,
        default=7.5,
        help="Guidance scale для генерации"
    )
    
    parser.add_argument(
        "--seed",
        type=int,
        default=None,
        help="Seed для воспроизводимости"
    )
    
    # Параметры обучения
    parser.add_argument(
        "--learning-rate",
        type=float,
        default=1e-4,
        help="Learning rate для обучения LoRA"
    )
    
    parser.add_argument(
        "--batch-size",
        type=int,
        default=1,
        help="Batch size для обучения"
    )
    
    parser.add_argument(
        "--num-epochs",
        type=int,
        default=10,
        help="Количество эпох обучения"
    )
    
    parser.add_argument(
        "--lora-rank",
        type=int,
        default=16,
        help="Rank для LoRA адаптера"
    )
    
    args = parser.parse_args()
    
    # Формируем конфигурацию обучения
    training_config = LoRATrainingConfig(
        rank=args.lora_rank,
        learning_rate=args.learning_rate,
        batch_size=args.batch_size,
        num_epochs=args.num_epochs,
        controlnet_types=args.controlnet_types,
    )
    
    # Параметры генерации
    generation_params = {
        "num_inference_steps": args.num_inference_steps,
        "guidance_scale": args.guidance_scale,
        "seed": args.seed,
    }
    
    # Запускаем пайплайн
    run_synthetic_generation_pipeline(
        jsonl_path=args.jsonl_path,
        output_dir=args.output_dir,
        images_root=args.images_root,
        lora_output_dir=args.lora_output_dir,
        lora_path=args.lora_path,
        skip_training=args.skip_training,
        num_samples_to_generate=args.num_samples,
        training_config=training_config,
        controlnet_types=args.controlnet_types,
        generation_params=generation_params,
    )


if __name__ == "__main__":
    main()

